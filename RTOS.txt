I, TASK CONTROL
	1 tạo task
		1.1 xTaskCreate():
		1.2 xTaskCreatePrintedToCore():
	2 thay đổi mức ưu tiên
		thay đổi mức ưu tiên vTaskPioritySet()
		lấy mức ưu tiên vTaskPiorityGet()
	3 đình chỉ tác vụ
		vTaskSuspend(): truyền NULL nếu tự đình chỉ chính nó
	4 phục hồi tác vụ
		vTaskResum() : chỉ gọi khi task bị suspend
	5 xoá tác vụ
		vTaskDelete()
II, QUEUE (FIFO)(Lưu trữ dữ liệu của task)
	1 Lưu trữ dữ liệu
	2 truy cập bởi nhiều tác vụ
	3 khoá quyền đọc hàng đợi
		- khi 1 tác vụ ra lệnh đọc hàng đợi nếu hàng đợi trống-> tác vụ sẽ block -> đi vào chế độ chờ-> chờ dữ liệu khả dụng từ hàng đợi
		- 1 tác vụ thoát khỏi chế độ block khi 1 task khác hoặc 1 ISR thực hiện lệnh ghi vào hàng đợi này
		- tác vụ đi vào trạng thái ready nếuthời gian chờ kết thúc
 		- nếu nhiều tác vụ đang đọc -> tác vụ nào đang unblock-> ưu tiên cao hơn. Nếu cùng mức ưu tiên-> tác vụ nào chờ lâu hơn thì được ưu tiên trước.

	4 khoá quyền ghi hàng đợi
		- khi 1 tác vụ ra lệnh ghi vào hàng đợi -> nó block nếuhàng đợi đang đầy
		- tác vụ được mở khoá -> luôn luôn là tác vụ có mức ưu tiên cáo nhất trong không gian khả dụng. Nếu các tác vụ bị khoá có mức ưu tiên bằng nhau thì tác vụ đang đợi không gian lâu nhất được unlock-> lưu vào hàng đợi
	5 khởi tạo hàng đợi
		xQueueCreate()
	6 ghi dữ liệu
		xQueueSendToFront(): ghi lên đầu hàng đợi
		xQueueSendToBack(): ghi vào cuối hàng đợi
		xQueueSendToForntFromISR()/xQueueSendToBackFromISR(): dùng trong ngắt
	7 đọc dữ liệu từ hàng đợi
		xQueueReceive()
		xQueueReceiveFromISR(...)
		xQueuePeek(...); hàm này là đọc dữ liệu mà không xóa mất dữ liệu trong hàng đợi.
	8 các hàm truy vấn trong hàng đợi
		uxQueueMessagesWaiting() và uxQueueMessagesWaitingFromISR() để trả về số lượng phần tử được lưu trữ trong hàng đợi
	9 xoá/ reset hàng đợi
		Sử dụng hàm xQueueDelete() để xóa hàng đợi, giải phóng tất cả bộ nhớ đã được cấp phát để lưu các phần tử của hàng đợi
	10 lưu ý
		Nếu các hàm Sender có Priority thấp hơn hàm Receiver thì hàng đợi luôn có ít hơn 1 phần tử dữ liệu, và hàm Sender thì không cần đặt time out vì nó sẽ thực hiện ngay lập tức. Ngược lại nếu là cao hơn.

		Với kiểu dữ liệu là kiểu cấu trúc thì phải là các trường dữ liệu để nhận diện được kiểu cấu túc đó của Sender nào gửi tới.

		Nếu dữ liệu cần lưu vào hàng đợi lớn hơn khả năng của hàng đợi thì ta chỉ cần lưu vào hàng đợi con trỏ nơi chứa dữ liệu đó.

III. SEMAPHORE TRONG FREERTOS
	Semaphore được dùng để: 

	Điều khiển truy cập tới một tài nguyên chia sẻ (loại trừ lẫn nhau – Mutex)

	Báo hiệu một sự kiện (event) xảy ra 

	Cho phép hai tác vụ đồng bộ hóa hoạt động của chúng

	Ý tưởng cơ bản: 

	Một semaphore chứa một số lượng token. Code cần nhận được một token để tiếp tục thực thi

	Nếu tất cả token của semaphore đã được sử dụng, tác vụ yêu cầu sẽ bị đình chỉ (suspended) cho đến khi một số token được giải phóng bởi các chủ sở hữu hiện tại của chúng

	Semaphore làm việc như thế nào? 

	§ Một semaphore có:

	Counter: Số lượng truy cập đồng thời tối đa

	Queue: Cho các tác vụ chờ truy cập

	§ Nếu một tác vụ yêu cầu (đợi - wait) một semaphore 

	Nếu counter> 0, thì (1) counter giảm đi 1 và (2) tác vụ nhận semaphore và tiến hành công việc của nó

	Ngược lại, tác vụ bị chặn (Block) và đưa vào queue

	§ Nếu một tác vụ giải phóng (đăng - post) một semaphore 

	Nếu có tác vụ trong hàng đợi semaphore, thì tác vụ thích hợp sẽ được chuẩn bị sẵn, theo chính sách xếp hàng

	Ngược lại, counter được tăng thêm 1

	Có 2 loại semaphore: Binary semaphore, Couting semaphore

	1. Binary Semaphore
	Binary Semaphore defintion

	Cho mục đích đồng bộ hóa, một semaphore nhị phân có thể được hiểu như một queue chỉ có một phần tử dữ liệu (item) 

	 Hàng đợi chỉ có thể trống hoặc đầy (do đó gọi là nhị phân)

	§ Các tác vụ sử dụng hàng đợi không quan tâm hàng đợi chứa gì, chỉ muốn biết hàng đợi trống hay đầy

	 Nếu có nhiều hơn một tác vụ khóa (lock) trên cùng một semaphore, thì tác vụ có mức ưu tiên cao nhất sẽ là tác vụ được unlock vào lần semaphore khả dụng tiếp theo (semaphore đầy)

	Nhiều tác vụ có thể sử dụng semaphore nhị phân trong một ứng dụng duy nhất. Nhưng chỉ có một nhiệm vụ có thể đạt được nó tại một thời điểm. Việc làm cho semaphore trở thành một tài nguyên toàn cục cho phép bất kỳ tác vụ nào giải phóng nó, ngay cả khi tác vụ ban đầu không có được nó.

	Deferred Interrupt Processing

	Cách tốt nhất để xử lý các sự kiện phức tạp do ngắt kích hoạt là không thực hiện mã trong ISR

	Tạo một tác vụ đang chặn (block) trên semaphore nhị phân 

	Khi ngắt xảy ra, ISR chỉ đặt (give) semaphore và thoát

	Tác vụ hiện tại có thể được lên lịch giống như bất kỳ tác vụ nào khác 

	Không cần phải lo lắng về việc lồng các ngắt (nesting interrupt) và mức độ ưu tiên của ngắt

	Điều này được gọi là Deferred Interrupt Processing

	Graphical user interfaceDescription automatically generated with low confidence

	Semaphore được tạo ở trạng thái “empty” (rỗng)

	Một semaphore nhị phân không cần được trả (give) lại sau khi lấy (take), do đó, đồng bộ hóa tác vụ có thể được thực hiện bởi một tác vụ/ngắt liên tục 'cấp' (give) semaphore trong khi một tác vụ khác liên tục 'lấy‘ (take) semaphore

	Semaphore nhị phân được gán cho các biến kiểu SemaphoreHandle_t và có thể được sử dụng trong bất kỳ hàm API nào nhận tham số kiểu này

	Tạo semaphore nhị phân: 

	SemaphoreHandle_t   xSemaphoreCreateBinary(void);
	Cấp (give) một semaphore nhị phân: 

	xSemaphoreGiveFromISR( SemaphoreHandle_t xSemaphore,
	signed BaseType_t *pxHigherPriorityTaskWoken)
	Reset (take) một semaphore nhị phân: xSemaphoreTake(xSemaphoreHandle xSemaphore,

	portTickType xBlockTime)
	2. Counting Semaphore
	Đếm sự kiện:

	Một trình xử lý sự kiện (event handler) sẽ 'cung cấp‘ (give) một semaphore mỗi khi một sự kiện xảy ra và một tác vụ xử lý (handler task) sẽ 'lấy' (take) một semaphore mỗi khi nó xử lý một sự kiện

	Quản lý tài nguyên: 

	Giá trị đếm cho biết số lượng tài nguyên khả dụng 

	Để có được một tài nguyên, một tác vụ phải lấy (take) một semaphore 

	Khi một tác vụ kết thúc với tài nguyên, nó 'trả lại' (give) semaphore đó

	SemaphoreHandle_t xSemaphoreCreateCounting( UBaseType_t uxMaxCount, UBaseType_t uxInitialCount)

	FreeRTOS Notları #5: Semaphore | mehmettopuz.net

	3. So sánh Binary Semaphore và Counting Semaphore
	DiagramDescription automatically generated

IV. MUTEX TRONG FREERTOS
	Về cơ bản thì MUTEX tương tự như bin Semaphore nhưng có tích thêm cơ chế “kế thừa mức ưu tiên” và được dùng cho mục đích loại trừ (hạn chế quyền truy cập vào resource của các task khác) chứ không phải là để đồng bộ như Semaphore.

	 Kế thừa mức ưu tiên: Khi task có mức ưu tiên cao hơn muốn take MUTEX trong khi task có mức ưu tiên thấp hơn đang giữ nó thì, mức ưu tiên của 2 task sẽ được tráo cho nhau, cho tới khi task kia give MUTEX thì mức ưu tiên sẽ hoàn trả lại như cũ. Cơ chế này được thiết kế nhằm chắc chắn rằng các task có mức ưu tiên cao chỉ ở trạng thái block trong thời gian ngắn nhất có thể nhằm tránh tình trạng deadlock của hệ thống.

	Được sử dụng cho việc loại trừ lẫn nhau, để tại một thời điểm chỉ một tác vụ sử dụng tài nguyên chia sẻ, ví dụ: file, dữ liệu, thiết bị, … 

	 Để truy cập tài nguyên chia sẻ, một tác vụ khóa mutex liên kết với tài nguyên

	 Tác vụ sở hữu mutex cho đến khi nó unlock mutex

	Mutex Management

	Khi 1 task muốn truy cập vào tài nguyên để thực thi nhiệm vụ thì sẽ take Mutex. Trong lúc đó, bất kì task nào muốn take Mutex đều bị block cho tới khi task đang giữ Mutex “give” về chỗ cũ.

	Có thể hiểu đơn giản Mutex giống như khóa tủ gửi đồ trong siêu thị, muốn mở được tủ khóa để cất đồ thì cần có chìa khóa, và sau khi dùng xong phải để chìa khóa về chỗ cũ cho người khác dùng.

	Graphical user interface

	Description automatically generated

	MỘT SỐ ĐIỂM KHÁC SO VS SEMAPHORE

	Task đang sở hữu mutex sẽ không bao giờ phải chờ task khác thực thi, còn task đang sở hữu semaphore thì có thể vẫn phải chờ task khác thực thi xong.

	Chỉ có task cầm mutex mới được give mutex, bất kì task nào cũng có thể give semaphore. Chính vì vậy trình phục vụ ngắt có thể give Semaphore nhưng đối với Mutex thì không.

	Có thể có nhiều Semaphore, nhưng chỉ có duy nhất 1 mutex.

	- Kết luận:

	Semaphore là một lựa chọn tốt hơn trong trường hợp có nhiều tài nguyên sẵn có. Trong trường hợp tài nguyên được chia sẻ duy nhất, mutex là lựa chọn tốt hơn.

V. TRUYỀN THÔNG LIÊN TÁC VỤ
	RTOS cho phép phát triển các hệ thống nhúng phức tạp. Bằng cách sử dụng các tác vụ (luồng) độc lập, mỗi tác vụ có ngữ cảnh riêng, ta có thể triển khai các chương trình có hành vi đa nhiệm bằng cách sử dụng một CPU duy nhất.

	Truyền thông giữa các tác vụ (giao tiếp giữa các tác vụ) là một khía cạnh quan trọng khi thiết kế một ứng dụng nhúng bằng RTOS.

	CƠ CHẾ GIAO TIẾP

	Chia sẻ bộ nhớ (memory sharing) 

	Cơ chế tín hiệu (signaling mechanism)

	Truyền thông điệp (message passing)

	1. Chia sẻ bộ nhớ (Memory sharing)
	Điều đầu tiên nghĩ đến như một cơ chế truyền thông tin giữa các tác vụ khác nhau là sử dụng vị trí bộ nhớ dùng chung.

	Điều quan trọng là bộ nhớ dùng chung được bảo vệ bằng mutex hoặc semaphore.

	Một ví dụ rất cơ bản về việc sử dụng vị trí bộ nhớ chia sẻ là một biến toàn cục (Global variable) 

	Mặc dù không có gì ngăn cản ta sử dụng một biến như vậy, nhưng nó không được khuyến khích vì có nhiều cách phức tạp hơn sẵn có như là phương tiện giao tiếp giữa các tác vụ.

	2. Cơ chế tín hiệu ( Signaling Mechanism)
	Là một dạng truyền thông cơ bản. Chỉ ra sự xuất hiện của một sự kiện và có thể sử dụng cho mục đích đồng bộ hóa 

	Ta đã đề cập đến một cơ chế như vậy được gọi là semaphore trong phần trước. 

	Hai cơ chế báo hiệu bổ sung được sử dụng rộng rãi trong các hệ điều hành thời gian thực: 

	Cờ sự kiện (event flags) 

	DiagramDescription automatically generated

	Event group: chủ yếu có hai thuật ngữ quan trọng là cờ sự kiện (event flag) và bit sự kiện (event bit).

	Event flag là một giá trị boolean là ‘0’ hoặc ‘1’. Các giá trị boolean này biểu thị sự xuất hiện hoặc không xảy ra của một sự kiện.

	Trong FreeRTOS, Biến EventBits_t được sử dụng để lưu trữ trạng thái của cờ sự kiện.

	Nếu giá trị của EventBits_t là 1 có nghĩa là một sự kiện liên quan đến bit cụ thể này xảy ra. Ngược lại, nếu EventBits_t = 0, sự kiện đã không xảy ra.

	Ví dụ, nếu giá trị event group là 0x92 (=1001 0010) nghĩa là chỉ sự kiện 1, 4, 7 xảy ra

	FreeRTOS event group example with Arduino

	Là các bit sử dụng để mã hóa thông tin cụ thể 
	Được sử dụng để đồng bộ hóa và truyền thông các tác vụ. 

	Nhóm các cờ sự kiện riêng lẻ được gọi là nhóm sự kiện (event group) hay tín hiệu (signal). 

	Cờ sự kiện có thể được sử dụng bởi các tác vụ và theo chương trình phục vụ ngắt (ISR). Một cờ sự kiện đơn lẻ (hoặc một nhóm) có thể được truy cập bởi nhiều tác vụ khác nhau.

	Thiết đặt kích cỡ event group: định nghĩa số bít cờ trong một event group đơn lẻ. Ta có thể lựa chọn bằng cách sử dụng hằng số configUSE_16_BIT_TICKS của FreeRTOSConfig.h. 

	Nếu configUSE_16_BIT_TICKS = 1, event group chứa 8 flags.

	Ngược lại nếu configUSE_16_BIT_TICKS = 0, event group bao gồm 24 flags.

	Các hàm API Event Groups

	xEventGroupCreate

	xEventGroupWaitBits

	xEventGroupSetBits

	xEventGroupSetBitsFromISR

	xEventGroupClearBits

	xEventGroupClearBitsFromISR

	xEventGroupGetBits

	xEventGroupGetBitsFromISR

	vEventGroupDelete

	Cờ tác vụ (task flags)

	Graphical user interface, applicationDescription automatically generated

	Là một dạng đặc biệt của event flag. Trong khi cờ sự kiện có thể được truy cập bởi tất cả tác vụ, cờ tác vụ được sử dụng để thông báo (notification) đến một tác vụ nhận đơn lẻ (single receiving task)

	 Các hoạt động phổ biến nhất có thể được thực hiện trên cờ tác vụ là:     

	Set/Clear flags của tác vụ cụ thể

	Wait on a flage to take a specific value

	RTOS: thread flags

	FreeRTOS: Task notifications

	Vì không có quy ước đặt tên nghiêm ngặt, có thể thấy các cơ chế này có tên hơi khác nhau trong các bản phân phối RTOS khác nhau, nhưng chức năng mà chúng phục vụ là khá giống nhau.

	3. Truyền thông điệp (Message Passing)
	Truyền thông điệp trực tiếp - Người gửi và người nhận thông điệp được xác định rõ ràng. 

	Truyền thông điệp gián tiếp – Các thông điệp được đặt trong các cấu trúc như hàng đợi thông điệp (message queue) hoặc hộp thư (mailbox) và nhiều tác vụ có quyền đọc/ghi.

	Message queue:

	Là bộ đệm dữ liệu với số lượng mục nhập (entry) hữu hạn. Mỗi entry có thể chứa dữ liệu có kích thước nhất định 

	Có thể được sử dụng để truyền dữ liệu giữa các tác vụ và giữa các chương trình phục vụ ngắt ISR với các tác vụ.

	Được triển khai dưới dạng bộ đệm FIFO an toàn cho luồng (thread-safe FIFO buffers).

	Các hành động cụ thể được định nghĩa trong RTOS trong trường hợp một tác vụ cố gắng ghi vào hàng đợi thông báo đầy (full) hoặc cố gắng đọc một hàng đợi thông báo trống (empty).

	A picture containing tableDescription automatically generated

	Tạo/xóa hàng đợi tin nhắn 

	Lấy số lượng tin nhắn hiện được lưu trữ trong hàng đợi  

	Đưa tin nhắn vào hàng đợi

	Nhận tin nhắn từ hàng đợi

	IconDescription automatically generated

	Ở đây ta có Ví dụ: Sử dụng hàng đợi tin nhắn để đệm dữ liệu

	Có hai tác vụ đang hoạt động ở các tốc độ khác nhau. Ta có thể sử dụng hàng đợi thông báo làm bộ đệm nếu một trong các tác vụ tạo ra một loạt các mẫu dữ liệu và tác vụ kia phải xử lý từng mẫu dữ liệu riêng lẻ với tốc độ cố định.

	Mailbox

	Có thể lưu trữ một dữ liệu có kích thước cụ thể (ví dụ: biến 32-bit) và có thể được triển khai dưới dạng hàng đợi một mục nhập (single-entry queue).

	Một mailbox duy nhất có thể được truy cập bởi nhiều tác vụ. 

	Trong một số bản phân phối RTOS, mailbox có thể có nhiều hơn một mục nhập, điều này làm cho chúng rất giống với một hàng đợi thông báo (message queue) trong phần trước.

	IconDescription automatically generated with low confidence

	Hoạt động điển hình có thể được thực hiện trên mailbox là:

	Create/delete a mailbox 

	Write to a mailbox

	Read a mailbox